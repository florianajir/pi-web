x-logging: &default-logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

services:
  ddns-updater:
    image: ghcr.io/qdm12/ddns-updater:v2.9
    container_name: pi-ddns-updater
    restart: unless-stopped
    environment:
      CONFIG: >-
        {"settings":[
        {"provider":"cloudflare","zone_identifier":"${CLOUDFLARE_ZONE_ID}","domain":"${HOST_NAME}","token":"${CLOUDFLARE_DNS_API_TOKEN}","ttl":1,"proxied":false},
        {"provider":"cloudflare","zone_identifier":"${CLOUDFLARE_ZONE_ID}","domain":"*.${HOST_NAME}","token":"${CLOUDFLARE_DNS_API_TOKEN}","ttl":1,"proxied":false}
        ]}
    volumes:
      - ddns_data:/updater/data
    healthcheck:
      test: ["CMD", "/updater/ddns-updater", "healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    <<: *default-logging
    mem_limit: 128m

  watchtower:
    container_name: pi-watchtower
    image: containrrr/watchtower:1.7.1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_SCHEDULE=0 0 3 * * *
      - WATCHTOWER_NO_RESTART=true
      - TZ=${TIMEZONE:-Europe/Paris}
    <<: *default-logging
    healthcheck:
      test: ["CMD", "/watchtower", "--health-check"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    mem_limit: 64m

  traefik:
    image: traefik:v3.6
    container_name: pi-traefik
    restart: unless-stopped
    environment:
      - CLOUDFLARE_DNS_API_TOKEN=${CLOUDFLARE_DNS_API_TOKEN:-}
    command:
      - "--log.level=INFO"
      - "--api.dashboard=true"
      - "--ping=true"
      # Entry Points
      - "--entrypoints.web.address=:80/tcp"
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      - "--entrypoints.websecure.address=:443/tcp"
      - "--entrypoints.websecure.http.middlewares=compress@docker,hsts@docker"
      - "--entrypoints.websecure.http.tls.certresolver=cloudflare"
      - "--entrypoints.websecure.http3=true"
      # Providers
      - "--providers.docker=true"
      - "--providers.docker.watch=true"
      - "--providers.docker.network=frontend"
      - "--providers.docker.exposedbydefault=false"
      # ACME (Cloudflare DNS-01)
      - "--certificatesresolvers.cloudflare.acme.email=${EMAIL}"
      - "--certificatesresolvers.cloudflare.acme.storage=/letsencrypt/acme.json"
      - "--certificatesresolvers.cloudflare.acme.dnschallenge.provider=cloudflare"
      - "--certificatesresolvers.cloudflare.acme.dnschallenge.delaybeforecheck=10"
    labels:
      - "com.example.description=Traefik reverse proxy"
      - "com.example.service=traefik"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.middlewares.compress.compress=true"
      - "traefik.http.middlewares.hsts.headers.stsSeconds=2592000"
      - "traefik.http.middlewares.lan.ipallowlist.sourcerange=${ALLOW_IP_RANGES:-192.168.1.0/24}"
      - "traefik.http.routers.traefik.middlewares=lan@docker"
      - "traefik.http.routers.traefik.entrypoints=websecure"
      - "traefik.http.routers.traefik.rule=Host(`traefik.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.tls=true"
      - "traefik.http.routers.traefik.tls.domains[0].main=${HOST_NAME:-pi.lan}"
      - "traefik.http.routers.traefik.tls.domains[0].sans=*.${HOST_NAME:-pi.lan}"
      - "traefik.http.services.traefik.loadbalancer.server.port=8080"
    ports:
      - "80:80"
      - "443:443"
    expose:
      - 8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_letsencrypt:/letsencrypt
    networks:
      - frontend
    <<: *default-logging
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    mem_limit: 256m

  netdata:
    image: netdata/netdata:v2.8
    container_name: pi-netdata
    restart: unless-stopped
    pid: host
    cap_add:
      - SYS_PTRACE
      - SYS_ADMIN
    security_opt:
      - apparmor:unconfined
    networks:
      - frontend
    expose:
      - 19999
    volumes:
      - netdata_config:/etc/netdata
      - netdata_lib:/var/lib/netdata
      - netdata_cache:/var/cache/netdata
      - /:/host/root:ro,rslave
      - /etc/passwd:/host/etc/passwd:ro
      - /etc/group:/host/etc/group:ro
      - /etc/localtime:/etc/localtime:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /etc/os-release:/host/etc/os-release:ro
      - /var/log:/host/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - NETDATA_CLAIM_TOKEN=${NETDATA_CLAIM_TOKEN:-}
      - NETDATA_CLAIM_URL=${NETDATA_CLAIM_URL:-}
      - NETDATA_CLAIM_ROOMS=${NETDATA_CLAIM_ROOMS:-}
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:19999/api/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "com.example.description=Netdata real-time monitoring"
      - "com.example.service=monitoring"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.netdata.rule=Host(`netdata.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.netdata.entrypoints=websecure"
      - "traefik.http.routers.netdata.middlewares=lan@docker"
      - "traefik.http.routers.netdata.tls=true"
      - "traefik.http.services.netdata.loadbalancer.server.port=19999"
    <<: *default-logging
    mem_limit: 512m

  portainer:
    image: portainer/portainer-ce:lts
    container_name: pi-portainer
    restart: unless-stopped
    networks:
      - frontend
    expose:
      - 9000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - portainer_data:/data
    labels:
      - "com.example.description=Portainer container management"
      - "com.example.service=monitoring"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.portainer.rule=Host(`portainer.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.portainer.entrypoints=websecure"
      - "traefik.http.routers.portainer.middlewares=lan@docker"
      - "traefik.http.routers.portainer.tls=true"
      - "traefik.http.services.portainer.loadbalancer.server.port=9000"
    <<: *default-logging
    healthcheck:
      test: ["CMD", "/portainer", "--version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    mem_limit: 256m

  pihole:
    image: pihole/pihole:2025.11.1
    container_name: pi-pihole
    restart: unless-stopped
    cap_add:
      - NET_ADMIN
      - SYS_NICE
    expose:
      - 53
      - 8082
    ports:
      - "53:53/tcp"
      - "53:53/udp"
    environment:
      TZ: ${TIMEZONE:-Europe/Paris}
      FTLCONF_webserver_api_password: ${PASSWORD:-admin}
      FTLCONF_webserver_allow_api_all_origins: "true"
      FTLCONF_dns_listeningMode: "all"
      FTLCONF_dns_upstreams: ${PIHOLE_DNS_UPSTREAMS:-8.8.8.8;8.8.4.4}
      FTLCONF_misc_dnsmasq_lines: "address=/${HOST_NAME:-pi.lan}/${HOST_LAN_IP:-192.168.1.30}"
      FTLCONF_webserver_port: 8082
      FTLCONF_dns_domain: ${HOST_NAME:-pi.lan}
    volumes:
      - pihole_data:/etc/pihole
      - ./config/pihole/dnsmasq.d:/etc/dnsmasq.d
    networks:
      frontend: {}
      lan:
        ipv4_address: ${PIHOLE_IP:-192.168.1.29}
    labels:
      - "com.example.description=Pi-hole DNS Ad-Blocker"
      - "com.example.service=pihole"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.pihole.rule=Host(`pihole.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.pihole.entrypoints=websecure"
      - "traefik.http.routers.pihole.tls=true"
      - "traefik.http.routers.pihole.middlewares=lan@docker"
      - "traefik.http.services.pihole.loadbalancer.server.port=8082"
    healthcheck:
      test: ["CMD", "dig", "@127.0.0.1", "cloudflare.com"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    <<: *default-logging
    mem_limit: 256m

  n8n:
    image: n8nio/n8n:2.8.2
    container_name: pi-n8n
    restart: unless-stopped
    expose:
      - 5678
    labels:
      - "com.example.description=n8n workflow automation"
      - "com.example.service=n8n"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.n8n.rule=Host(`n8n.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.n8n.entrypoints=websecure"
      - "traefik.http.routers.n8n.tls=true"
      - "traefik.http.routers.n8n.middlewares=lan@docker"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"
    environment:
      - N8N_HOST=n8n.${HOST_NAME:-pi.lan}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://n8n.${HOST_NAME:-pi.lan}/
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE:-${TIMEZONE:-Europe/Paris}}
      - TZ=${TIMEZONE:-Europe/Paris}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=${N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS:-true}
      - DB_TYPE=sqlite
      - DB_SQLITE_POOL_SIZE=2
    volumes:
      - n8n_data:/home/node/.n8n
      - ./data/n8n/files:/files
    networks:
      - frontend
    <<: *default-logging
    depends_on:
      - traefik
    healthcheck:
      # n8n listens internally on plain HTTP. Use explicit IPv4 loopback to avoid IPv6 (::1) resolution issues.
      test:
        [
          "CMD",
          "wget",
          "-q",
          "-O",
          "/dev/null",
          "http://127.0.0.1:5678/healthz",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    mem_limit: 512m

  nextcloud:
    image: nextcloud:32-apache
    container_name: pi-nextcloud
    restart: unless-stopped
    environment:
      - NEXTCLOUD_ADMIN_USER=${USER:-admin}
      - NEXTCLOUD_ADMIN_PASSWORD=${PASSWORD:-admin}
      - NEXTCLOUD_ADMIN_EMAIL=${EMAIL:-admin@example.com}
      - NEXTCLOUD_TRUSTED_DOMAINS=nextcloud.${HOST_NAME:-pi.lan}
      - NEXTCLOUD_DATA_DIR=/var/www/html/data
      - OVERWRITEHOST=nextcloud.${HOST_NAME:-pi.lan}
      - OVERWRITEPROTOCOL=https
      - TRUSTED_PROXIES=${NEXTCLOUD_TRUSTED_PROXIES:-172.30.11.0/24}
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${NEXTCLOUD_DB_NAME:-nextcloud}
      - POSTGRES_USER=${NEXTCLOUD_DB_USER:-nextcloud}
      - POSTGRES_PASSWORD=${NEXTCLOUD_DB_PASSWORD:-nextcloud-secure-password}
      - REDIS_HOST=redis
      - TZ=${TIMEZONE:-Europe/Paris}
    volumes:
      - nextcloud_data:/var/www/html
    networks:
      - frontend
      - nextcloud
    labels:
      - "com.example.description=Nextcloud self-hosted storage"
      - "com.example.service=nextcloud"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.nextcloud.rule=Host(`nextcloud.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.nextcloud.entrypoints=websecure"
      - "traefik.http.routers.nextcloud.middlewares=lan@docker"
      - "traefik.http.routers.nextcloud.tls=true"
      - "traefik.http.services.nextcloud.loadbalancer.server.port=80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/status.php"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    <<: *default-logging
    mem_limit: 1g

  # Connectivity Stack
  headscale:
    image: headscale/headscale:stable
    container_name: pi-headscale
    restart: unless-stopped
    command: serve
    environment:
      - HEADSCALE_SERVER_URL=https://headscale.${HOST_NAME:-pi.lan}
      - HEADSCALE_LISTEN_ADDR=0.0.0.0:8080
      - HEADSCALE_DNS_BASE_DOMAIN=tailnet.${HOST_NAME:-pi.lan}
    networks:
      - frontend
    expose:
      - 8080
      - 9090
      - 50443
    ports:
      - "3478:3478/udp"
    volumes:
      - ./config/headscale:/etc/headscale:ro
      - headscale_data:/var/lib/headscale
      - headscale_run:/var/run/headscale
    labels:
      - "com.example.description=Headscale coordination server"
      - "com.example.service=headscale"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.headscale.rule=Host(`headscale.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.headscale.entrypoints=websecure"
      - "traefik.http.routers.headscale.tls=true"
      - "traefik.http.routers.headscale.tls.certresolver=cloudflare"
      - "traefik.http.routers.headscale.tls.domains[0].main=${HOST_NAME:-pi.lan}"
      - "traefik.http.routers.headscale.tls.domains[0].sans=*.${HOST_NAME:-pi.lan}"
      - "traefik.http.services.headscale.loadbalancer.server.port=8080"
    <<: *default-logging
    healthcheck:
      test: ["CMD", "/ko-app/headscale", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    mem_limit: 256m

  tailscale:
    image: tailscale/tailscale:stable
    container_name: pi-tailscale
    restart: unless-stopped
    network_mode: host
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    environment:
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_EXTRA_ARGS=--login-server=https://headscale.${HOST_NAME:-pi.lan} --accept-dns=true --advertise-exit-node --advertise-routes=192.168.1.0/24 --accept-routes
      - TS_HOSTNAME=tailscale.${HOST_NAME:-pi.lan}
    volumes:
      - tailscale_state:/var/lib/tailscale
      - /dev/net/tun:/dev/net/tun
    depends_on:
      - headscale
    healthcheck:
      test: ["CMD", "tailscale", "status", "--peers=false"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    labels:
      - "com.example.description=Tailscale VPN client (Headscale)"
      - "com.example.service=tailscale"
    <<: *default-logging
    mem_limit: 256m

  immich-server:
    container_name: pi-immich
    image: ghcr.io/immich-app/immich-server:v2
    restart: unless-stopped
    volumes:
      - ${IMMICH_UPLOAD_LOCATION:-./data/immich}:/data
      - /etc/localtime:/etc/localtime:ro
    environment:
      DB_TYPE: postgresql
      DB_HOSTNAME: postgres
      DB_PORT: 5432
      DB_USERNAME: ${IMMICH_DB_USER:-immich}
      DB_PASSWORD: ${IMMICH_DB_PASSWORD:-immich-secure-password}
      DB_DATABASE_NAME: ${IMMICH_DB_NAME:-immich}
      REDIS_HOSTNAME: redis
      REDIS_PORT: 6379
      REDIS_DBINDEX: 0
      NODE_ENV: production
      TZ: ${TIMEZONE:-Europe/Paris}
    networks:
      - frontend
      - immich
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    expose:
      - 2283
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:2283/api/server/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.example.description=Immich media server"
      - "com.example.service=immich"
      - "traefik.enable=true"
      - "traefik.docker.network=frontend"
      - "traefik.http.routers.immich.rule=Host(`immich.${HOST_NAME:-pi.lan}`)"
      - "traefik.http.routers.immich.entrypoints=websecure"
      - "traefik.http.routers.immich.middlewares=lan@docker"
      - "traefik.http.routers.immich.tls=true"
      - "traefik.http.services.immich.loadbalancer.server.port=2283"
    <<: *default-logging
    mem_limit: 1g

  redis:
    container_name: pi-redis
    image: docker.io/valkey/valkey:9@sha256:546304417feac0874c3dd576e0952c6bb8f06bb4093ea0c9ca303c73cf458f63
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
    restart: always
    networks:
      - immich
      - nextcloud
    labels:
      - "com.example.description=Redis cache for Immich & Nextcloud"
      - "com.example.service=redis"
    <<: *default-logging
    mem_limit: 256m

  postgres:
    container_name: pi-postgres
    image: ghcr.io/immich-app/postgres:14-vectorchord0.4.3-pgvectors0.2.0@sha256:bcf63357191b76a916ae5eb93464d65c07511da41e3bf7a8416db519b40b1c23
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD:-secure-password}
      POSTGRES_USER: ${DB_USERNAME:-postgres}
      POSTGRES_DB: ${DB_DATABASE_NAME:-postgres}
      POSTGRES_INITDB_ARGS: "--data-checksums"
      # Immich database vars
      IMMICH_DB_NAME: ${IMMICH_DB_NAME:-immich}
      IMMICH_DB_USER: ${IMMICH_DB_USER:-immich}
      IMMICH_DB_PASSWORD: ${IMMICH_DB_PASSWORD:-immich-secure-password}
      # Nextcloud database vars
      NEXTCLOUD_DB_NAME: ${NEXTCLOUD_DB_NAME:-nextcloud}
      NEXTCLOUD_DB_USER: ${NEXTCLOUD_DB_USER:-nextcloud}
      NEXTCLOUD_DB_PASSWORD: ${NEXTCLOUD_DB_PASSWORD:-nextcloud-secure-password}
      # Uncomment the DB_STORAGE_TYPE: 'HDD' var if your database isn't stored on SSDs
      # DB_STORAGE_TYPE: 'HDD'
    volumes:
      - ${DB_DATA_LOCATION:-./data/postgres}:/var/lib/postgresql/data
      - ./config/postgres/init-databases.sh:/docker-entrypoint-initdb.d/01-init-databases.sh
    shm_size: 128mb
    restart: always
    networks:
      - immich
      - nextcloud
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USERNAME:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    <<: *default-logging
    mem_limit: 2g
    labels:
      - "com.example.description=PostgreSQL database for Immich & Nextcloud"
      - "com.example.service=postgres"

volumes:
  ddns_data:
    labels:
      - "com.example.description=DDNS updater state"
      - "com.example.service=network"
  traefik_letsencrypt:
    labels:
      - "com.example.description=Traefik ACME certificates"
      - "com.example.service=proxy"
  netdata_config:
    labels:
      - "com.example.description=Netdata configuration"
      - "com.example.service=monitoring"
  netdata_lib:
    labels:
      - "com.example.description=Netdata library data"
      - "com.example.service=monitoring"
  netdata_cache:
    labels:
      - "com.example.description=Netdata cache data"
      - "com.example.service=monitoring"
  portainer_data:
    labels:
      - "com.example.description=Portainer persistent data"
      - "com.example.service=monitoring"
  pihole_data:
    labels:
      - "com.example.description=Pi-hole configuration data"
      - "com.example.service=dns"
  n8n_data:
    labels:
      - "com.example.description=n8n persistent data"
      - "com.example.service=automation"
  nextcloud_data:
    labels:
      - "com.example.description=Nextcloud application data"
      - "com.example.service=cloud"
  headscale_data:
    labels:
      - "com.example.description=Headscale persistent data and keys"
      - "com.example.service=headscale"
  headscale_run:
    labels:
      - "com.example.description=Headscale runtime socket"
      - "com.example.service=headscale"
  tailscale_state:
    labels:
      - "com.example.description=Tailscale persistent state"
      - "com.example.service=tailscale"

networks:
  frontend:
    driver: bridge
    name: frontend
    ipam:
      driver: default
      config:
        - subnet: 172.30.11.0/24
          gateway: 172.30.11.1
    labels:
      - "com.example.description=External Web Network"
      - "com.example.service=proxy"
  lan:
    driver: macvlan
    name: lan
    driver_opts:
      parent: ${HOST_LAN_PARENT:-eth0}
    ipam:
      driver: default
      config:
        - subnet: ${HOST_LAN_SUBNET:-192.168.1.0/24}
          gateway: ${HOST_LAN_GATEWAY:-192.168.1.1}
    labels:
      - "com.example.description=Physical LAN macvlan for DHCP"
      - "com.example.service=pihole"
  nextcloud:
    driver: bridge
    name: nextcloud
    internal: true
    labels:
      - "com.example.description=Nextcloud application network"
      - "com.example.service=nextcloud"
  immich:
    driver: bridge
    name: immich
    internal: true
    labels:
      - "com.example.description=Immich application network"
      - "com.example.service=immich"
